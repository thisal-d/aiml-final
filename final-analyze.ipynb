{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79dd756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Performance Analysis Notebook\n",
    "\n",
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.precision', 4)\n",
    "sns.set(style=\"whitegrid\", font_scale=1.1)\n",
    "\n",
    "# 2. Load All CSV Files\n",
    "files = [\n",
    "    \"./results/metrics/decision_tree.csv\",\n",
    "    \"./results/metrics/knn.csv\",\n",
    "    \"./results/metrics/logistic_regression.csv\",\n",
    "    \"./results/metrics/mlp.csv\",\n",
    "    \"./results/metrics/random_forest.csv\",\n",
    "    \"./results/metrics/xgboost.csv\"\n",
    "]\n",
    "\n",
    "# Read and merge\n",
    "dataframes = []\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Combine all\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e50c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning / Preparation\n",
    "# Extract model name and version\n",
    "combined_df['Model_Name'] = combined_df['Model'].apply(lambda x: x.split(' - ')[0])\n",
    "combined_df['Version'] = combined_df['Model'].apply(lambda x: x.split(' - ')[1])\n",
    "\n",
    "# Reorder columns\n",
    "cols = ['Model_Name', 'Version', 'Accuracy', 'Precision', 'Recall', 'F1_Score', 'AUC_ROC']\n",
    "combined_df = combined_df[cols]\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2515ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Best Models for each metric\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1_Score', 'AUC_ROC']\n",
    "\n",
    "best_models = {}\n",
    "for metric in metrics:\n",
    "    idx = combined_df[metric].idxmax()\n",
    "    best_models[metric] = combined_df.loc[idx, ['Model_Name', 'Version', metric]]\n",
    "\n",
    "best_models_df = pd.DataFrame(best_models).T\n",
    "best_models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7400a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "\n",
    "# -- a. Bar Plot for Each Metric (showing all 4 versions per model) --\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(12,6))\n",
    "    sns.barplot(data=combined_df, x='Model_Name', y=metric, hue='Version', palette='viridis')\n",
    "    plt.title(f'{metric} Comparison Across All Model Versions')\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel('Model')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title='Version')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -- b. Heatmap of all model performances --\n",
    "plt.figure(figsize=(12, 10))\n",
    "# Create a combined label for the heatmap\n",
    "combined_df['Model_Version'] = combined_df['Model_Name'] + ' - ' + combined_df['Version']\n",
    "heatmap_data = combined_df.set_index('Model_Version')[metrics]\n",
    "\n",
    "sns.heatmap(heatmap_data, annot=True, cmap='YlGnBu', fmt='.4f', linewidths=.5)\n",
    "plt.title('Model Performance Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaccd90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Model for each metric\n",
    "for metric in metrics:\n",
    "    best_model = combined_df.loc[combined_df[metric].idxmax()]\n",
    "    print(f\"Best Model for {metric}: {best_model['Model_Name']} - {best_model['Version']} ({best_model[metric]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d005cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Best Model (All Metrics Combined)\n",
    "\n",
    "# Compute mean performance of each model across all metrics\n",
    "overall_df = (\n",
    "    combined_df.groupby(['Model_Name', 'Version'])\n",
    "    [metrics].mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Normalize metrics to [0, 1] scale for fair comparison\n",
    "normalized_df = overall_df.copy()\n",
    "for metric in metrics:\n",
    "    min_val = normalized_df[metric].min()\n",
    "    max_val = normalized_df[metric].max()\n",
    "    normalized_df[metric] = (normalized_df[metric] - min_val) / (max_val - min_val)\n",
    "\n",
    "# Compute an overall score (average of all normalized metrics)\n",
    "normalized_df['Overall_Score'] = normalized_df[metrics].mean(axis=1)\n",
    "\n",
    "# Find the best model overall\n",
    "best_overall = normalized_df.loc[normalized_df['Overall_Score'].idxmax()]\n",
    "print(\"Best Overall Model (Across All Metrics):\")\n",
    "print(f\"Model: {best_overall['Model_Name']} - {best_overall['Version']}\")\n",
    "print(f\"Overall Score: {best_overall['Overall_Score']:.4f}\")\n",
    "\n",
    "# Plot overall scores\n",
    "plt.figure(figsize=(12,8))\n",
    "normalized_df['Model_Version'] = normalized_df['Model_Name'] + ' - ' + normalized_df['Version']\n",
    "sns.barplot(\n",
    "    data=normalized_df.sort_values('Overall_Score', ascending=False),\n",
    "    x='Model_Version', y='Overall_Score', palette='coolwarm'\n",
    ")\n",
    "plt.title('Overall Performance Across All Metrics')\n",
    "plt.ylabel('Normalized Average Score (0-1)')\n",
    "plt.xlabel('Model Version')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display top 5 models\n",
    "top5 = normalized_df.sort_values('Overall_Score', ascending=False).head(5)\n",
    "print(\"\\nTop 5 Models:\")\n",
    "for idx, row in top5.iterrows():\n",
    "    print(f\"{row['Model_Name']} - {row['Version']}: {row['Overall_Score']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
